{"pageType": "article", "pathParams": {"slug": "padstone-terraform-for-deployment"}, "locals": {"article": {"body": "<p><a href=\"http://packer.io/\" target=\"_blank\">Packer</a> and <a href=\"https://terraform.io/\" target=\"_blank\">Terraform</a> are the products <a href=\"https://hashicorp.com/\" target=\"_blank\">HashiCorp</a> recommends for building and deploying\napplications in the modern datacenter, but these two tools have some differences and\nrough edges that mean they don't tessellate as well as they could. In this article\nI'll talk about a prototype I built that uses the core of Terraform to create a Packer\nreplacement, creating a more flexible tool that has a much better story for integration\nwith Terraform for deployment.</p><section id=\"the-hashicorp-stack\"><h3>The HashiCorp Stack</h3><p>Modern web applications are rarely composed of just a managed application server\nand a database, but are rather composed of a wide array of different services: CDNs\nand load balancers, smart DNS servers, externally-managed storage and caching\ninfrastructure, outsourced mail servers, and so on and so on.</p><p>Traditional application deployment most commonly makes a sharp distinction between\nthe the deployment of code and the management of the infrastructure on which the\ncode runs and which the code uses. Tools like Puppet, Chef and cfengine are primarily\nfocused on automating the configuration of particular servers, with separate tooling\nlike Foreman for bootstrapping those servers and, in many cases, home-grown scripts\ndoing the actual deployment of applications.</p><p><a href=\"https://terraform.io/\" target=\"_blank\">Terraform</a> is an open source project by <a href=\"https://hashicorp.com/\" target=\"_blank\">HashiCorp</a> that takes a new angle on\ncloud infrastructure and application deployment. It takes the declarative resource\ndefinition style of Puppet but applies it to the definition of resources that\ncan be created, updated and deleted via network APIs. In a world of cloud-hosted\ninfrastructure, that can include everything from DNS records to virtual machines to\ngit repositories. While Terraform's current set of resources is weighted towards\ninfrastructure-as-a-service platforms, its model is suitably generic \u2014 just\nCreate, Read, Update and Delete operations \u2014 that it can be readily applied to\njust about anything that could be reasonably modelled as a REST API resource.</p><p>As well as a resource-oriented configuration language for API-managed objects,\nTerraform's other key feature is its concept of <em>state</em>, which allows Terraform not\nonly to create resources but to keep track of previously-created resources and\nupdate and delete them as needed. The current state of one deployment can be used\nas an input to another, so as well as <em>managing</em> infrastructure Terraform can\nalso be seen as a way of <em>publishing</em> and <em>sharing</em> infrastructure between\nteams within an organization.</p><p>Deploying in terms of API-managed resources works best when applications\nare <em>built</em> in terms of such services. One certainly <em>could</em> provision a\nstock Ubuntu EC2 instance with Terraform and then from then on install\nsoftware on it via a traditional \"copy-files-flip-symlink-restart\" workflow,\nif we produce an \"Amazon Machine Image\" (AMI) with the application already\ninstalled then we can have Terraform deploy it directly, and benefit from\nthe fast startup time that comes from having done most of the setup work\nat application build time rather than at deploy time.</p><p>HashiCorp's answer to this need is <a href=\"http://packer.io/\" target=\"_blank\">Packer</a>, a tool which in fact predates\nTerraform and is designed to automate the creation of machine images for\nvarious cloud infrastructure platforms. Its model is pretty simple:</p><ul><li><p>A <em>builder</em> spins up an environment based on an existing image and prepares\nthat environment so Packer can interact with it.</p></li><li><p>One or more <em>provisioners</em> communicate with the created environment to\ncustomize it in arbitrary ways. For example, a <tt>chef-solo</tt> provisioner\nallows Chef to be used to apply changes to the machine.</p></li><li><p>The builder then captures some kind of image of the build environment,\nwhich becomes the <em>artifact</em> of the build.</p></li></ul><p>When applied to AWS, the builder creates an EC2 instance, the provisioners\ninteract with it over SSH, and then the final artifact is an AMI that can\nbe used as the basis for new instances created at deployment time.</p></section><section id=\"putting-the-pieces-together\"><h3>Putting the Pieces Together</h3><p>Perhaps due to it predating Terraform by some years, the interopability between\nPacker and Terraform is unfortunately rather limited. If you wish to move beyond\nmanually pasting the ids of the generated artifacts into your Terraform\nconfiguration, you're left either with parsing Packer's rather awkward (but\ncertainly machine-readable) CSV output, or running Packer inside HashiCorp's\n<a href=\"https://atlas.hashicorp.com/\" target=\"_blank\">Atlas</a> platform. Either way it doesn't feel completely natural, and that's rather\nunfortunate for two tools that supposedly belong to the same family.</p><p>Along with the frustration of the poor tessellation of these tools, I also\ncouldn't shake the idea that Packer's high-level capabilities are pretty close\nto being a subset of Terraform's capabilities.</p></section><section id=\"build-vs-deploy-not-so-different\"><h3>Build vs. Deploy: Not so different?</h3><p>When we put aside various implementation details and the set of resources that happen to\nbe implemented in each codebase today, there are only a few minor differences\nbetween the build process afforded by Packer and the deployment process afforded\nby Terraform:</p><ul><li><p>Terraform manages a set of long-lived resources across multiple incremental deployments.\nPacker produces a completely distinct set of resources for each run.</p></li><li><p>Terraform creates and updates resources to move them towards a configured end state.\nPacker provisions certain resources only to assist in the build process, destroying them\nonce the process is complete.</p></li><li><p>Terraform keeps track of the resources it's created, so they can be updated and deleted\nby later runs. Packer cedes control of the resources it created as soon as it completes,\nleaving the user to do manual cleanup.</p></li></ul><p>The first two of these are legitimate and fundamental differences in purpose between the build\nand deployment phases. The last of these is arguably a limitation of Packer: though there is little\nreason to <em>alter</em> the artifacts of a build, it would actually be rather useful to be able to\nautomatically destroy resources created for older versions of an app that are no longer needed\nin order to reduce storage costs.</p><p>The first two differences also apply to the use of Puppet or Chef as a one-off image provisioning\ntool vs. their use for ongoing management of a long-lived machine. If these tools can be applied\nto both problems, and if Terraform's configuration is at a similar level of expressive power\nto Puppet's, perhaps we could apply the resource management guts of Terraform to both problems\nalso.</p></section><section id=\"padstone-a-terraform-build-prototype\"><h3>Padstone: A Terraform Build Prototype</h3><p>I created <a href=\"https://github.com/apparentlymart/padstone\" target=\"_blank\">Padstone</a> to explore the idea of applying Terraform's model to the problem of building\napplication artifacts. Padstone is a small command line tool that puts a new, build-oriented fa\u00e7ade\non the underlying mechanisms of Terraform.</p><p>The most readily-obvious difference between Padstone and Terraform is that the set of subcommands\nit accepts are more oriented around an application build workflow:</p><pre class='terminal'>$ padstone --help\nUsage:\n  padstone [OPTIONS] &lt;build | destroy | publish&gt;\n\nHelp Options:\n  -h, --help  Show this help message\n\nAvailable commands:\n  build    Run a build and produce a state file\n  destroy  Destroy the results of a build\n  publish  Publish a state file to remote storage</pre><section id=\"executing-builds-with-padstone\"><h4>Executing builds with Padstone</h4><p>The <tt>padstone build</tt> command expects as arguments:</p><ul><li><p>a path to a directory containing Terraform-like configuation files (named with a <tt>.pad</tt>\nextension, a superset of standard Terraform config as we will see in a moment)</p></li><li><p>a path at which a state file will be created to record the results of the build process</p></li><li><p>zero or more values to populate the user variables defined in the configuration</p></li></ul><p>Much like <tt>terraform apply</tt>, <tt>padstone build</tt> uses Terraform providers and provisioners to\ncreate various resources and then records the state of these resources in a JSON state file.\n<em>Unlike</em> Terraform, Padstone always starts with an empty state and thus creates a fresh set of\nresources for each run, thus addressing the first of our differences from the section above.\nOne down, one to go!</p></section><section id=\"temporary-build-infrastructure\"><h4>Temporary Build Infrastructure</h4><p>To address the second of the differences I noted, Padstone extends the Terraform configuration\nmodel with the concept of a <em>temporary resource</em>. A temporary resource is created the same way\nas any other resource, except that <tt>padstone build</tt> will destroy all of the temporary resources\nbefore it returns.</p><p>At the time of writing, Terraform lacks a resource type for creating an AMI, which is the main\npurpose of the AWS family of builders in Packer. However, AMIs can be created via the API just\nlike any other resource, so it's a simple matter to extend Terraform to support these API functions,\nas I did in <a href=\"https://github.com/hashicorp/terraform/pull/2784\" target=\"_blank\">Terraform pull request #2784</a>. I used a build of Terraform with that patch applied\nin order to illustrate how Padstone can achieve the same result as Packer.</p><p>The following Padstone config builds an AMI via a similar process to that used by Packer's\n<tt>amazon-ebs</tt> builder and Chef provisioner:</p><p>We can put this config in <tt>webserver/ami.pad</tt> and then create an AMI for a particular application\nwith Padstone as follows:</p><pre class='terminal'>$ padstone build webserver/ webserver-0.0.1.tfstate version=0.0.1 \\\n       vpc_id=vpc-xxxxxxxx subnet-id=subnet-xxxxxxxx\n\n[aws_key_pair.provision] Creating...\n[aws_security_group.ssh] Creating...\n[aws_instance.base] Creating...\n[aws_instance.base] Provisioning...\n[aws_ami_from_instance.image] Creating...\n--- Build succeeded! Now destroying temporary resources... ---\n[aws_instance.base] Destroying...\n[aws_key_pair.provision] Destroying...\n[aws_security_group.ssh] Destroying...\n\nOutputs:\n- version = 0.0.1\n- ami_id = ami-xxxxxxxx</pre><p>With this extra step of destroying the temporary resources we resolve the second difference between\ndeploy and build. Throughout the process Padstone maintains the current resource state in\nthe <tt>webserver-0.0.1.tfstate</tt>, and so once the process is complete it contains just the outputs\nand the non-temporary resources.</p></section><section id=\"cleaning-up\"><h4>Cleaning Up</h4><p>As noted above, Packer provides no automatic way to destroy the resources it created once they are\nno longer needed. By writing out a state file, Padstone can overcome this limitation of Packer:</p><pre class='terminal'>$ padstone destroy webserver/ webserver-0.0.1.tfstate version=0.0.1 \\\n       vpc_id=vpc-xxxxxxxx subnet-id=subnet-xxxxxxxx\n\n[aws_ami_from_instance.image] Destroying...\nAll resources destroyed</pre><p>All that's required to benefit from this is to record somewhere the state file for each version.\nFor example, if the build process is being orchestrated by Jenkins then its ability to capture\nfiles as artifacts could be used to attach the state to the Jenkins build result.</p></section><section id=\"publishing-artifacts\"><h4>Publishing Artifacts</h4><p>The original motivation for Padstone was to create a build tool that integrates well with Terraform.\nThis is achieved by publishing the state file that describes the created resources,\nso that it can be imported into a Terraform deployment using the <tt>terraform_remote_state</tt>\nresource:</p><pre class='terminal'>$ padstone publish webserver-0.0.1.tfstate s3 \\\n       region=us-west-2 bucket=padstone-results \\\n       key=exampleapp/webserver-0.0.1.tfstate</pre><p>As long as whoever is running the deployment has access to the same S3 bucket, this state can\nbe used by replicating the same settings in the Terraform configuration:</p><p>Of course, since all Terraform resources are available in Padstone it is also possible for one\nPadstone configuration to consume resources from another, allowing the build process get the same\ncollaboration benefits as Terraform brings to the deployment process.</p></section><section id=\"how-padstone-works\"><h4>How Padstone Works</h4><p>Padstone re-uses a <em>lot</em> of code from Terraform. It has its own top-level configuration parser\nin order to support the temporary resources, and of course the implementation of its unique\ncommands, but really all it's doing is transforming its input into something that the Terraform\ncore can consume and then running the same old \"apply\" and \"destroy\" steps.</p><p>The concept of temporary resources is implemented via some trickery: Terraform's dependency resolver\nwouldn't normally allow a resource to be destroyed without also destroying its dependents, but\nPadstone is able to break this rule by splitting the internal state data structure in two,\nmaintaining the temporaries and the results as separate manifests. The temporaries can then be\ncleaned up by destroying the state where the results are excluded, causing Terraform to temporarily\n\"forget\" that the result resources exist.</p><p>The full details are, of course, in <a href=\"https://github.com/apparentlymart/padstone\" target=\"_blank\">the code</a>.</p></section></section><section id=\"where-to-from-here\"><h3>Where to from here?</h3><p>In its current state, Padstone is just a prototype and far from ready to use. Although it's shown\nthat there's potential for a superior solution compared to Packer, the set of resources supported\nin today's Terraform does not include all of the items that Packer can produce.</p><p>However, with the right set of Terraform resources Padstone could push beyond Packer's narrow focus\non machine images to many other per-app-version resource types. For example:</p><ul><li><p>A resource for creating objects in S3 buckets could be used to distribute arbitrary files, like\nlibrary archives for use in other builds, or application archives to deploy with AWS OpsWorks.</p></li><li><p>A provider for <a href=\"https://www.fastly.com/\" target=\"_blank\">Fastly</a> could exploit the concept of configuration versions that's built in to\ntheir API in order to push new configurations at build time and simply activate them at\ndeploy time.</p></li><li><p>Padstone could be used to create a separate set of EC2 instances for each application version,\nand then have Terraform manage only the load balancer in front of them to support quick rollback\nto the still-running older version in the event of issues. The instances for each version can\nthen have their own independent lifecycle. Similar thinking could apply to any other kind of\nresource that's deployed behind some sort of switching layer that allows backend resource\nselections to change quickly.</p></li><li><p>In principle, Padstone could benefit from Terraform providers that manipulate local resources\non the system where Padstone is running. This is not appropriate for standard Terraform since\nthose resources would usually not be available to other users of the created state, but Padstone\ncould use them as <em>temporary</em> resources to assist in the creation of a non-local result resource,\nsuch as running VirtualBox locally to create a machine image that is ultimately upladed to S3,\nor registered in <a href=\"https://atlas.hashicorp.com/\" target=\"_blank\">Atlas</a> as a shared Vagrant box.</p></li></ul><p>At the moment I have no strong wish to develop and maintain a competitor to Packer. Rather I'm\nsharing this proof-of-concept in the hope of stimulating a discussion about ways in which these\nproblems could be solved in a more integrated, flexible manner by the \"HashiCorp stack\". I feel\nthat such a project would be far more successful if lead and coordinated by a team whose full\ntime job is creating DevOps tools. Never say never, though!</p></section>", "mainImageUrl": "/padstone-terraform-for-deployment/None", "title": "Padstone: Terraform for Software Builds", "url": "/padstone-terraform-for-deployment/", "summary": "A prototype of using Terraform's core functionality for software builds.", "date": "2015-07-19", "type": "DevOps Tools"}}, "path": "/:slug/"}